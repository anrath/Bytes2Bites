{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Maybe you called ray.init twice by accident? This error can be suppressed by passing in 'ignore_reinit_error=True' or by calling 'ray.shutdown()' prior to 'ray.init()'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, Callable, List\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_cpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.11/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.11/site-packages/ray/_private/worker.py:1589\u001b[0m, in \u001b[0;36minit\u001b[0;34m(address, num_cpus, num_gpus, resources, labels, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, log_to_driver, namespace, runtime_env, storage, **kwargs)\u001b[0m\n\u001b[1;32m   1587\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m RayContext(\u001b[38;5;28mdict\u001b[39m(_global_node\u001b[38;5;241m.\u001b[39maddress_info, node_id\u001b[38;5;241m=\u001b[39mnode_id\u001b[38;5;241m.\u001b[39mhex()))\n\u001b[1;32m   1588\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1589\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1590\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaybe you called ray.init twice by accident? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1591\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis error can be suppressed by passing in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1592\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore_reinit_error=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1593\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mray.shutdown()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m prior to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mray.init()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1594\u001b[0m         )\n\u001b[1;32m   1596\u001b[0m _system_config \u001b[38;5;241m=\u001b[39m _system_config \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_system_config, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Maybe you called ray.init twice by accident? This error can be suppressed by passing in 'ignore_reinit_error=True' or by calling 'ray.shutdown()' prior to 'ray.init()'."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict, Callable, List\n",
    "import ray\n",
    "ray.init(num_cpus=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figuring out groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined based on the logic you are doing\n",
    "def grouped_mean_chunk(df: pd.DataFrame, groupCols: List, selectCol: str, **kwargs) -> pd.DataFrame:\n",
    "    return df.groupby(groupCols)[selectCol].agg(['count', 'sum'])\n",
    "\n",
    "# Defined based on the logic you are doing\n",
    "def grouped_mean_agg(df: pd.DataFrame, rename: str, groupCols: List, **kwargs) -> pd.DataFrame:\n",
    "    df = df.reset_index()\n",
    "    agg_df = df.groupby(groupCols).agg(total_sum=('sum', 'sum'), total_count=('count', 'sum'))\n",
    "    agg_df[rename] = agg_df.apply(lambda row: row['total_sum'] / row['total_count'], axis=1)\n",
    "    \n",
    "    return agg_df[rename].reset_index()\n",
    "\n",
    "# Will not be changed\n",
    "@ray.remote\n",
    "def process_chunk(chunk: pd.DataFrame, dfMethod: Callable, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the mean of specified columns, grouped by a specified category, for a given DataFrame chunk.\n",
    "\n",
    "    Args:\n",
    "    - chunk (pd.DataFrame): A chunk of the DataFrame.\n",
    "    - dfMethod (Callable): A function that takes in a dataframe as an input and returns a dataframe\n",
    "    - **kwargs: Additional keyword arguments to pass to dfMethod.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame\n",
    "    \"\"\"\n",
    "    return dfMethod(chunk, **kwargs)\n",
    "\n",
    "# Will not be changed\n",
    "def process_file(file_path: str, dfMethod: Callable, aggMethod: Callable, separator: str = '\\t', **kwargs) -> None:\n",
    "    \"\"\"\n",
    "    Process a large CSV file to compute grouped means for specified columns and save the results.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): The path to the CSV file.\n",
    "    - dfMethod (Callable): A function that takes in a dataframe (chunk) as an input and returns a dataframe\n",
    "    - aggMethod (Callable): A function that aggregates the concatenated results from all chunks\n",
    "    - separator (str): delimiter for the input file\n",
    "    - **kwargs: Additional keyword arguments to pass to both dfMethod and aggMethod.\n",
    "    \"\"\"\n",
    "    chunk_size = 1000  # Define chunk size based on system's memory.\n",
    "\n",
    "    results = []\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunk_size, sep=separator, low_memory=False):\n",
    "        result = process_chunk.remote(chunk, dfMethod, **kwargs)\n",
    "        results.append(result)\n",
    "\n",
    "    # Retrieve and combine results from all chunks.\n",
    "    combined_results = pd.concat(ray.get(results))\n",
    "\n",
    "    # Uncomment for debugging purposes. \n",
    "    # combined_results.to_csv(\"data/grouped_means_combined.csv\", index=True)\n",
    "\n",
    "    # Final aggregation to ensure accurate mean calculation across all chunks.\n",
    "    final_result = aggMethod(combined_results, **kwargs)\n",
    "\n",
    "    final_result.to_csv(\"data/grouped_means_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5152/1186209857.py:9: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  agg_df[rename] = agg_df.apply(lambda row: row['total_sum'] / row['total_count'], axis=1)\n"
     ]
    }
   ],
   "source": [
    "groupCols = ['food_groups_en']\n",
    "selectCol = 'ecoscore_score'\n",
    "rename = 'mean_ecoscore_score'\n",
    "\n",
    "process_file(\n",
    "    file_path='data/small_subset.csv',\n",
    "    dfMethod=grouped_mean_chunk,\n",
    "    aggMethod=grouped_mean_agg,\n",
    "    separator=',',\n",
    "    groupCols=groupCols,\n",
    "    selectCol=selectCol,\n",
    "    rename=rename\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ray.remote\n",
    "# def calculate_nan_percentage(chunk: pd.DataFrame) -> Dict[str, float]:\n",
    "#     \"\"\"\n",
    "#     Calculate the percentage of NaN values in each column of a given DataFrame chunk.\n",
    "\n",
    "#     Args:\n",
    "#     - chunk (pd.DataFrame): A chunk of the DataFrame.\n",
    "\n",
    "#     Returns:\n",
    "#     - Dict[str, float]: A dictionary with column names as keys and percentages of NaN values as values.\n",
    "#     \"\"\"\n",
    "#     nan_counts = chunk.isna().sum()\n",
    "#     return (nan_counts / len(chunk) * 100).to_dict()\n",
    "\n",
    "# def process_large_csv(file_path: str) -> None:\n",
    "#     \"\"\"\n",
    "#     Process a large CSV file to compute the percentage of NaN rows in each column and save the results.\n",
    "\n",
    "#     Args:\n",
    "#     - file_path (str): The path to the CSV file.\n",
    "#     \"\"\"\n",
    "#     # Define chunk size - you might need to adjust this based on your system's memory.\n",
    "#     chunk_size = 50000  \n",
    "\n",
    "#     # Read the CSV in chunks and process each chunk in parallel, specifying the delimiter as '\\t' for tab.\n",
    "#     results = []\n",
    "#     for chunk in pd.read_csv(file_path, chunksize=chunk_size, sep='\\t', low_memory=False):\n",
    "#         result = calculate_nan_percentage.remote(chunk)\n",
    "#         results.append(result)\n",
    "\n",
    "#     # Combine results from all chunks.\n",
    "#     combined_results = ray.get(results)\n",
    "#     final_result = pd.DataFrame(combined_results).mean().to_dict()\n",
    "\n",
    "#     # Save the final result to a file.\n",
    "#     with open(\"data/nan_percentage_results.txt\", \"w\") as f:\n",
    "#         for column, percentage in final_result.items():\n",
    "#             f.write(f\"{column}\\t{percentage:.2f}%\\n\")\n",
    "\n",
    "#     print(\"Completed processing. The NaN percentages have been saved to nan_percentage_results.txt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_large_csv('data-testing/raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/nan_percentage_results.txt', sep='\\t', header=None)\n",
    "# df.columns = ['column', 'percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['percentage'] = df['percentage'].str.replace('%', '').astype(float)\n",
    "# df = df[df['percentage'] < 95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize a new column 'duplicated' with empty strings\n",
    "# df['duplicated'] = ''\n",
    "\n",
    "# # Process only the rows with non-zero percentages\n",
    "# non_zero_df = df[df['percentage'] != 0].copy()\n",
    "\n",
    "# # Group by 'percentage' and aggregate the columns, skipping the first one\n",
    "# for _, group in non_zero_df.groupby('percentage'):\n",
    "#     if len(group) > 1:\n",
    "#         duplicated_columns = group['column'].iloc[1:].tolist()\n",
    "#         first_index = group.index[0]\n",
    "#         df.at[first_index, 'duplicated'] = ', '.join(duplicated_columns)\n",
    "\n",
    "# # Remove the duplicated rows except for the first occurrence\n",
    "# df = df.drop(non_zero_df[non_zero_df.duplicated('percentage', keep='first')].index).reset_index(drop=True)\n",
    "# df.to_csv('data/nan_percentage_results_filtered.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
